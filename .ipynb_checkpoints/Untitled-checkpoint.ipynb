{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import tokenizers\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 510\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "EPOCHS = 6\n",
    "PATH = \"bert_config\" #！！！需要改 config所在为止 我用的预训练模型注意下！！！\n",
    "TRAINING_FILE = \"train_data_frame.csv\" #！！！需要改\n",
    "dev_file = 'dev_deleted.csv'\n",
    "TOKENIZER = transformers.BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm-ext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_config = transformers.RobertaConfig.from_pretrained(PATH)\n",
    "#model_config.output_hidden_states = True\n",
    "#MODEL = transformers.AutoModel.from_pretrained(\"hfl/chinese-roberta-wwm-ext\", config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ans(text, answer):\n",
    "    for index in (i for i, e in enumerate(text) if e == answer[0]):\n",
    "            if text[index:index+len(answer)] == answer:\n",
    "                idx0 = index\n",
    "                idx1 = index + len(answer)\n",
    "                return idx0, idx1\n",
    "    return find_start(text, answer[:-1])\n",
    "\n",
    "def find_text(ans_start, ans_end, text, posslen):\n",
    "    text_l = ans_start\n",
    "    text_r = ans_end\n",
    "    count = 0\n",
    "    for i in text[ans_end:]:\n",
    "        if i==\"。\":\n",
    "            text_r += 1\n",
    "            break\n",
    "        else:\n",
    "            text_r += 1\n",
    "    text_l = text_r - posslen\n",
    "    return text_l, text_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(text, question, answer, tokenizer, max_len):\n",
    "    len_ans = len(answer)\n",
    "    posslen = max_len - len(question) - 3\n",
    "    \n",
    "    ans_start, ans_end = find_ans(text, answer)\n",
    "    text_l, text_r = find_text(ans_start, ans_end, text, posslen)\n",
    "    if len(text) > posslen:\n",
    "        text = text[text_l:text_r]\n",
    "    token_text = tokenizer.encode_plus(text,question)\n",
    "    input_ids_orig = token_text[\"input_ids\"]\n",
    "        \n",
    "    input_ids = input_ids_orig\n",
    "    token_type_ids = [0] * (len(input_ids_orig))\n",
    "    mask = [1] * len(token_type_ids)\n",
    "    if ans_start>=510:\n",
    "        ans_start=0\n",
    "    if ans_end>=510:\n",
    "        ans_end=0\n",
    "    if ans_start<=0:\n",
    "        ans_start = 0\n",
    "    if ans_end<=0:\n",
    "        ans_end=0\n",
    "    ans_start += 1   #\n",
    "    ans_end += 1       #\n",
    "    \n",
    "    padding_length = max_len - len(input_ids)\n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + ([1] * padding_length)\n",
    "        mask = mask + [0] * padding_length\n",
    "        token_type_ids = token_type_ids + [0] * padding_length\n",
    "        \n",
    "    return {\n",
    "        'ids': input_ids,\n",
    "        'mask': mask,\n",
    "        'token_type_ids': token_type_ids,\n",
    "        'ans_start': ans_start,\n",
    "        'ans_end': ans_end,\n",
    "        'orig_text': text,\n",
    "        'orig_ans': answer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAdataset:\n",
    "    def __init__(self, text, question, answer):\n",
    "        self.text = text\n",
    "        self.question = question\n",
    "        self.answer = answer\n",
    "        self.tokenizer = TOKENIZER\n",
    "        self.max_len = MAX_LEN\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        data = process_data(\n",
    "            self.text[item],\n",
    "            self.question[item],\n",
    "            self.answer[item],\n",
    "            self.tokenizer,\n",
    "            self.max_len\n",
    "            )\n",
    "        return {\n",
    "            'ids': torch.tensor(data[\"ids\"], dtype=torch.long),\n",
    "            'mask': torch.tensor(data[\"mask\"], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(data[\"token_type_ids\"], dtype=torch.long),\n",
    "            'ans_start': torch.tensor(data[\"ans_start\"], dtype=torch.long),\n",
    "            'ans_end': torch.tensor(data[\"ans_end\"], dtype=torch.long),\n",
    "            'orig_text': data[\"orig_text\"],\n",
    "            'orig_ans': data[\"orig_ans\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAmodel(transformers.BertForQuestionAnswering):\n",
    "    def __init__(self, conf):\n",
    "        super(QAmodel,self).__init__(conf)\n",
    "        self.bertwwm = transformers.BertModel.from_pretrained(\"hfl/chinese-bert-wwm-ext\", config=conf)\n",
    "        self.drop_out = nn.Dropout(0.2)\n",
    "        self.out = nn.Linear(768 * 2, 2)\n",
    "        torch.nn.init.normal_(self.out.weight, std=0.02)\n",
    "        \n",
    "    def forward(self, input_ids, mask, token_type_ids):\n",
    "        _, _, out = self.bertwwm(input_ids, token_type_ids=token_type_ids, attention_mask=mask)\n",
    "        out = torch.cat((out[-1], out[-2]), dim=-1)\n",
    "        out = self.drop_out(out)\n",
    "        #out  = out.view(510,8, 768*2)\n",
    "        logits = self.out(out)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "        return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(start_logits, end_logits, start_positions, end_positions):\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    start_loss = loss_fct(start_logits, start_positions)\n",
    "    end_loss = loss_fct(end_logits, end_positions)\n",
    "    total_loss = (start_loss + end_loss)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QAmodel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (bertwwm): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (drop_out): Dropout(p=0.2, inplace=False)\n",
       "  (out): Linear(in_features=1536, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_fn(data_loader, model, optimizer, device, scheduler=None):\n",
    "    model.train()\n",
    "    \n",
    "    for bi, d in enumerate(data_loader):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        ans_start = d[\"ans_start\"]\n",
    "        ans_end = d[\"ans_end\"]\n",
    "        orig_ans = d[\"orig_ans\"]\n",
    "        orig_text = d[\"orig_text\"]\n",
    "        \n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        ans_start = ans_start.to(device, dtype=torch.long)\n",
    "       # ans_start = ans_start.squeeze(-1)  #  修改了\n",
    "        ans_end = ans_end.to(device, dtype=torch.long)\n",
    "        #ans_end = ans_end.squeeze(-1) #  修改了\n",
    "        \n",
    "        model.zero_grad()\n",
    "        outputs_start, outputs_end = model(ids, mask, token_type_ids)\n",
    "        #print(outputs_start.shape)\n",
    "        #outputs_s = outputs_start.view(8,510)\n",
    "        #outputs_e= outputs_end.view(8,510)\n",
    "        #print(outputs_s.shape)\n",
    "        loss = loss_fn(outputs_start, outputs_end, ans_start, ans_end)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "        \n",
    "df_train = pd.read_csv(TRAINING_FILE)\n",
    "train_dataset = QAdataset(\n",
    "    text=df_train.context.values,\n",
    "    question=df_train.question.values,\n",
    "    answer=df_train.answer.values\n",
    ")\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "device = torch.device('cuda:1') #!!!需要改成\"cuda\"\n",
    "model_config = transformers.BertConfig.from_pretrained(PATH)\n",
    "model_config.output_hidden_states = True\n",
    "model = QAmodel(conf=model_config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "#no_decay = [\"weight_hh_l0\", 'bias_ih_l0', 'weight_ih_l0','bias_hh_l0']\n",
    "#optimizer_parameters = [\n",
    "#    {'params': [p for n, p in param_optimizer if  any(nd in n for nd in no_decay)], 'weight_decay': 0.001}\n",
    "    #{'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],'weight_decay': 0.0},\n",
    "    #{'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],'weight_decay': 0.0},\n",
    "#]\n",
    "optimizer_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if  any(nd in n for nd in no_decay)], 'weight_decay': 0.001}#if not any(nd in n for nd in no_decay)\n",
    "    #{'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}    #if any(nd in n for nd in no_decay)\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_parameters, lr=2e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=num_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.2647, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.9421, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4458, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0831, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4576, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3247, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7587, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7790, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8540, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4349, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5673, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3290, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(13.1908, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(13.2021, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8396, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(13.2587, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6899, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0951, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7407, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(13.1450, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1260, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4395, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(13.2678, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6535, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6474, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7545, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(13.0485, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7993, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8538, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(13.3931, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7586, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4551, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6927, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(13.2053, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6063, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5310, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.9125, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8676, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1007, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5325, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4537, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3233, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.9895, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0663, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6935, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2934, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5556, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8192, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4580, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3073, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6966, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2051, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7901, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3202, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2014, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4184, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8632, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7648, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5926, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(13.1387, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8166, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3499, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0492, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2652, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8221, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2430, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8416, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4031, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5996, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1425, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(13.0310, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9270, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4018, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2570, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6297, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0069, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6559, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5548, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8568, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3033, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8203, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.9059, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7354, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9116, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5777, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3471, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4240, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(13.1267, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6284, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4207, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4968, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7324, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8337, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7605, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0704, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8337, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4914, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.9507, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8030, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5842, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8004, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(13.0820, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2374, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5261, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4294, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7357, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4557, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7704, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5018, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2180, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1489, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3650, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4917, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0252, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5568, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7402, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0022, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6700, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8476, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8201, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9350, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3057, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5705, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4495, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2760, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6316, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5328, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2044, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8922, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4146, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3154, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2387, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0645, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0822, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8157, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3373, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5008, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4907, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8113, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5752, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0623, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3541, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6597, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1592, device='cuda:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.7770, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5005, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6823, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2360, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3823, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6702, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(13.1822, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5954, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8671, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7557, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1722, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2958, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0368, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4389, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2602, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3154, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9223, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1137, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0807, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1386, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0829, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7001, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5748, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4215, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6525, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2330, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2283, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1276, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1159, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0778, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3208, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1986, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.9025, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5036, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8585, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6340, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0987, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6077, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9997, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3662, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2329, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2940, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4034, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8892, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6079, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6315, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8121, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3674, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9735, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6439, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0683, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3222, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4188, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2203, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7387, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7464, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2015, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0988, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8592, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9131, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3616, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7709, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2030, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3602, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1495, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3630, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9314, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5464, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7322, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6601, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9753, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9949, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9299, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1608, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7190, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1538, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0603, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7974, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2992, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7630, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9644, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6720, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4392, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4443, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8367, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8128, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1768, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9867, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3802, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0451, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8564, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7835, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0261, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8489, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4854, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9262, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4708, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9921, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7334, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2000, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4206, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0477, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5020, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8852, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9575, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4883, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9811, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4654, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6261, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7988, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8544, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5215, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3545, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4181, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9176, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0603, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7091, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9934, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9451, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0342, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2282, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4507, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4234, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4692, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3947, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6243, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5316, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2728, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8501, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9569, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2968, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3963, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8356, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4613, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(13.0347, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7924, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1629, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1082, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3515, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7015, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4530, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4498, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0138, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1789, device='cuda:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.8679, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3348, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2121, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8333, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1400, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8456, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3710, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0177, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7868, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9948, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0826, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2347, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2715, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3638, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4472, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0081, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1204, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9010, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4884, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0079, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4506, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3633, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3521, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9405, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2171, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2961, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6921, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4440, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0380, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1292, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1636, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0807, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7591, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0324, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6636, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7137, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0109, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7447, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9728, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7493, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7861, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9978, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7929, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2035, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6310, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7170, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7617, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1942, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2879, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7725, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9306, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6473, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7098, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4696, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7669, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0399, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0588, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5850, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3169, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2941, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5252, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9602, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0705, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1187, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8291, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9452, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9163, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0020, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8145, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3842, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8597, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0521, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8471, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9084, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4021, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8460, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7461, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6046, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6154, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4311, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2735, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4984, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0744, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3326, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7292, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3037, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1325, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7119, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3277, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7197, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2182, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5642, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8331, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1141, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8821, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4306, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1523, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1639, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9898, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6853, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1806, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1828, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8918, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3662, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7703, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8565, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9225, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3044, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6417, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0383, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8804, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1581, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3624, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4236, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4613, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3635, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2402, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2876, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6205, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0193, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8549, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9906, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8607, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4319, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4654, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9956, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5181, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8928, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0139, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3309, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7159, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5778, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9283, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9538, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8509, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0134, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5788, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8927, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6339, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4354, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0475, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3544, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9839, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1881, device='cuda:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.2780, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3381, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7563, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4210, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6006, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2518, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1842, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2307, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3678, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3955, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7450, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3751, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8419, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7930, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0755, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7327, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4313, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6786, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1688, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4975, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1872, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4339, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2477, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7248, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1153, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2658, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1627, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9163, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5423, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8072, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7085, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1433, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5826, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8032, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3289, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9676, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5897, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8963, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7503, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6208, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9953, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8097, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3755, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1550, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7640, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3843, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2583, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3574, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8995, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1308, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5456, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5683, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4682, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0975, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7381, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5731, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0500, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3538, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7772, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0645, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1828, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7956, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3580, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1551, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5132, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2583, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4214, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0952, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1948, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4536, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6812, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5344, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8295, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4634, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4875, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3288, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4776, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7161, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5995, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8392, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4591, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7059, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0673, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7764, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6071, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4881, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8929, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7327, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0927, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7598, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2100, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6181, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1244, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5916, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4452, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8379, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9310, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2480, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7109, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6226, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1383, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9691, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4380, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9625, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1758, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5264, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2314, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9350, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0454, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5865, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9408, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5488, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0880, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2165, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9778, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8727, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2409, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3301, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2955, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9525, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1522, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4345, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8185, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7565, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3439, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6013, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7014, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5991, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9864, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4355, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2661, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6018, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7994, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5787, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3348, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6168, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9938, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0293, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.8370, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5993, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1525, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8586, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3739, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1996, device='cuda:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.2453, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7571, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8847, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.6130, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3497, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5143, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3650, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6656, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5140, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4003, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1181, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6797, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8847, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6890, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5757, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1875, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8445, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0936, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3347, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1949, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5912, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4381, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9628, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3648, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1817, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9845, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9523, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6647, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6040, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0032, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9994, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5053, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6236, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1520, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8131, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9169, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4583, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8718, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6178, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7533, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3717, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8207, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3206, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8601, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1358, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1461, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0848, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5560, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6006, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7615, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9677, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8118, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8707, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5534, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1532, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9875, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0537, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.9155, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8617, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5966, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4375, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6242, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8562, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5602, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8484, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9138, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4958, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6084, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1529, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5087, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9006, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5560, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8534, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5525, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4621, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3724, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0840, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3510, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8241, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8646, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3693, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7002, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3884, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2474, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0642, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5497, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3434, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0603, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4876, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6187, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7507, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2879, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9505, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6168, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3892, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7017, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1996, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4179, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2234, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1137, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0873, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7171, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6843, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2498, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2874, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9610, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9840, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5448, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1503, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3960, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2103, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4827, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8000, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4929, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5334, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1830, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8585, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3685, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1945, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6753, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5197, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8697, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9719, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5533, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6897, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8077, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5232, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8014, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3385, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3115, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2572, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7028, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5183, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0178, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1434, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0627, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7047, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2376, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3111, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1528, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1969, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2097, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0587, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3465, device='cuda:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.9713, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9114, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5048, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9018, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4011, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1524, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9335, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1437, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1927, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6945, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7140, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4702, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7533, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1513, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4479, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3391, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5362, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6208, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4793, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5157, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9059, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4008, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9170, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0079, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1186, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7676, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9344, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8281, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2297, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5465, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2799, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0831, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2590, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6302, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4203, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2098, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8124, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2505, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2927, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6621, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8730, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2392, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3508, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5332, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0329, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9776, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3451, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4198, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3023, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6563, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5803, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2075, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0687, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5844, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6556, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3363, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9779, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6495, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9868, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0990, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2402, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6635, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8446, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3009, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5298, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2770, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0216, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3103, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0900, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1657, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5743, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1598, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6538, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6099, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4428, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9627, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9600, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4824, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7970, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9814, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4540, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2839, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3925, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5613, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0178, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5110, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6516, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7220, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3483, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7987, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2595, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8366, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6598, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6315, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9906, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5162, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3663, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4417, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2555, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0097, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6727, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6377, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0023, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0862, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.2746, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8795, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1963, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4918, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2987, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7550, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4114, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2528, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1844, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3621, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9064, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0171, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1329, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2061, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2320, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1782, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5159, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5191, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1197, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1825, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4848, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8212, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9787, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7907, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7086, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3238, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5396, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5501, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5854, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5276, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9207, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.3705, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6229, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9153, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6019, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4487, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0311, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3148, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8475, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4193, device='cuda:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.3971, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0930, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5520, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9025, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1348, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5268, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7723, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4212, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9844, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1729, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2577, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3909, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1105, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5989, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3023, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1861, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0922, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3083, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7491, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2616, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0871, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7159, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2750, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6560, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3114, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0354, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5024, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5346, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0878, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7224, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7966, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0761, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3503, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4080, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8835, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2693, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0825, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6347, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4216, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1681, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7701, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9817, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4464, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8907, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1452, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1536, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4728, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8662, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8123, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6544, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1697, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5749, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7948, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5204, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0488, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8655, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6647, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5894, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3523, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2300, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0142, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7367, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6708, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8363, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0954, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8389, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7695, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8698, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4230, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4653, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.4053, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5185, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9223, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3954, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6886, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8797, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7270, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3575, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1480, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8990, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5833, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4578, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7025, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4920, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4273, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3952, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6694, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3673, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3717, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6486, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1716, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3690, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4647, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2973, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2690, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1464, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7949, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6855, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8486, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9560, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9473, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0792, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1758, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4381, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5839, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4939, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7818, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7041, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5240, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5452, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3567, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0565, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0514, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3467, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5533, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1708, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2677, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8611, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2301, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9293, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4112, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0548, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5432, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0554, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0525, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3134, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7725, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9047, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0646, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5187, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9723, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6211, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4943, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5542, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9248, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5767, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3623, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4368, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2553, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4465, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1772, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.0359, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2579, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5559, device='cuda:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.0545, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5654, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8460, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8134, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4773, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9553, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8508, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6713, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8514, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4543, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6550, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9205, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0091, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6408, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4704, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4712, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9191, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3054, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9557, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9322, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8577, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2920, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1264, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3478, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.0512, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0612, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0927, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5290, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4434, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8742, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6234, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2101, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8926, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3244, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1277, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.2229, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4925, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4817, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.0642, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7451, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7530, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4174, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1950, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1384, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7706, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8052, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1670, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7584, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9668, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8074, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8211, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8237, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7067, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8828, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(9.9166, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4389, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0884, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.0551, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8656, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9550, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7993, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1879, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3384, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.2810, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9760, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8424, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.2048, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4780, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0472, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0621, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0505, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9548, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8704, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5682, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1415, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3148, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0239, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8541, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8921, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.9910, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8878, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3730, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2101, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8303, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5839, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8985, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2539, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1601, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5612, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7583, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1968, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4962, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5589, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8025, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2136, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5908, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3074, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9190, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7367, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7960, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7700, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8532, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9071, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8515, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7234, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5474, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8122, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.2628, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9215, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6069, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2658, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6296, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3472, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6795, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0169, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3667, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5674, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3765, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8982, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4522, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.2499, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0436, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7679, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8594, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9319, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9487, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9202, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3825, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1708, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1785, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5860, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5498, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4928, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7064, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.7051, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1401, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6163, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1794, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0842, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5271, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7547, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6437, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9614, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4918, device='cuda:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.3214, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8151, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7664, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9603, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4527, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1300, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0939, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9547, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0396, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.2668, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7154, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3409, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4901, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.2586, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1483, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7724, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7779, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7900, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8763, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9296, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5716, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6047, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1689, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8991, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9083, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2800, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8998, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8285, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8624, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8415, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.2980, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5589, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7687, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9539, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7323, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(9.8931, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5796, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(9.6230, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1236, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0325, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7027, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2353, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.2454, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4065, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4076, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9579, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3229, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3334, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5143, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1141, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.1550, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1803, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4391, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.0829, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0562, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0676, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4531, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3702, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9819, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2285, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.0659, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6301, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7360, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3812, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6980, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4996, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0510, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9294, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1622, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5741, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3734, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1363, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3176, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7665, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5469, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.2453, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0390, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8100, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0646, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.2491, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1936, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6088, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4970, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9601, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6908, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1782, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0171, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4299, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9211, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6667, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0909, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9123, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9254, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7068, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3026, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6321, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7420, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6375, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8736, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0084, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.0566, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5272, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6618, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4798, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3771, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1861, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9143, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4412, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.2594, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3316, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3303, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1418, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6858, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6053, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5193, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3671, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9763, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(9.9547, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9692, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.2867, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3991, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4647, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5085, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.2778, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2530, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.2816, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6347, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.0190, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3866, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0281, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8690, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7801, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7293, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7644, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7619, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5243, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5347, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(9.9590, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0105, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4739, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6371, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3528, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5868, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5574, device='cuda:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.3364, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8635, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8070, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6926, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7700, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7666, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3195, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1475, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4828, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7188, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1674, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4328, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8349, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5895, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1228, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9215, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1564, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3053, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(9.8974, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0126, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0224, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1239, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3010, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1105, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8204, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8478, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5300, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4360, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7172, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3470, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9239, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4429, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8156, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4176, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1073, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1967, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.4577, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6707, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(9.7912, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5259, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3010, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6922, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5172, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4202, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6543, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.5360, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6156, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6936, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7090, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.8477, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(9.9797, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9193, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1189, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2027, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3425, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3560, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7618, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1237, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1462, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7417, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.0771, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6390, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5269, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4213, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3632, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1333, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.6530, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8838, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0559, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(12.5588, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5906, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6771, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8779, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8934, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7252, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4736, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0998, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5938, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4134, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0591, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3446, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9569, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7853, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3925, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.5535, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3405, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3227, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1318, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8686, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.6507, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(9.7517, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1886, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9692, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8899, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.3335, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(9.8086, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.4737, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(9.8668, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.1759, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0329, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.7334, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1893, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(9.8973, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3603, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.2502, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0800, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8682, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3449, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(11.0135, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.1439, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.8977, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3320, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.9210, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.7980, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.0118, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "tensor(10.3277, device='cuda:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THC/THCReduceAll.cuh:327",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-69133f5c1a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"over epoch-------------------------\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#torch.save(model, 'QAdev.pt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'QAdev_params.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-fe217fbc4102>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(data_loader, model, optimizer, device, scheduler)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#print(outputs_s.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TFboys/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TFboys/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TFboys/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TFboys/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mnonzero_finite_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THC/THCReduceAll.cuh:327"
     ]
    }
   ],
   "source": [
    "for epoch in range(8):\n",
    "    train_fn(train_data_loader, model, optimizer, device, scheduler=scheduler)\n",
    "    print(\"over epoch-------------------------\", epoch)\n",
    "#torch.save(model, 'QAdev.pt')   \n",
    "torch.save(model.state_dict(), 'QAdev_params.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAdatasetvalid:\n",
    "    def __init__(self, text,question):\n",
    "        self.text = text\n",
    "        self.question = question\n",
    "        self.tokenizer = TOKENIZER\n",
    "        self.max_len = MAX_LEN\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        data = process_datavalid(\n",
    "            self.text[item],\n",
    "            self.question[item],\n",
    "            self.tokenizer,\n",
    "            self.max_len\n",
    "            )\n",
    "        \n",
    "        return{\n",
    "            'ids': torch.tensor(data[\"ids\"], dtype=torch.long),\n",
    "            'mask': torch.tensor(data[\"mask\"], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(data[\"token_type_ids\"], dtype=torch.long),\n",
    "            'orig_text': data[\"orig_text\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_FILE = 'test_data_with_stp.csv'\n",
    "df_valid = pd.read_csv(VALID_FILE)\n",
    "valid_dataset = QAdatasetvalid(\n",
    "    text=df_valid.context.values,#\n",
    "    question=df_valid.id.values,\n",
    ")\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    tk0 = tqdm(valid_data_loader, total=len(valid_data_loader))\n",
    "    for bi, d in enumerate(tk0):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        orig_text = d[\"orig_text\"]\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "\n",
    "        outputs_start, outputs_end = model(\n",
    "            ids,\n",
    "            mask,\n",
    "            token_type_ids\n",
    "        )\n",
    "\n",
    "        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "        idx_start=np.argmax(outputs_start)\n",
    "        idx_end=np.argmax(outputs_end)\n",
    "        out = orig_text[0][int(idx_start)-1:int(idx_end)-1]\n",
    "        answer_list.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_dict = {}\n",
    "for i in range(df_valid.shape[0]):\n",
    "    key = df_valid.loc[i]['question']\n",
    "    value = answer_list[i]\n",
    "    answer_dict[key] = value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for k,v in answer_dict.items():\n",
    "    print(k,v)\n",
    "    i=i+1n\n",
    "    if i >50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "outfile = 'answer_json_27.json'\n",
    "with open(outfile,'w') as f:\n",
    "    json.dump(answer_dict,f, ensure_ascii=False) # 解决中文编码问题"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
